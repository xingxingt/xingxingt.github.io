---
layout:     post
title:      Spark初识
subtitle:   
date:       2018-08-28
author:     XINGXING
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Spark
---

>
>spark初识篇
> 

 ![](https://github.com/xingxingt/xingxingt.github.io/tree/master/img/blog-img/spark-runtime.png)

###  Spark HA的情况下,zookeeper中存放了哪些数据信息:

    master，worker，application的信息

### Application

    Application 是由Driver部分和executor部分组成，而Driver驱动executor的执行
    
### Driver

    Spark Driver部分由sparkConf和sparkContext组成
    如下Driver部分代码:
        
    ` /**
      * 第一步:创建Spark的配置对象SparkConf，设置Spark程序的运行时的配置信息
      * 例如说通过setMaster来设置程序要连接的Spark集群的Master的URL
      * 如果设置为local，则代表Spark程序在本地运行，特别适合于配置条件的较差的人
      *
      */

    val conf = new SparkConf()
    conf.setAppName("wordCountLocal") //设置应用程序的名称，在程序运行的监控界面可以看到名称
    conf.setMaster("local") //此时程序在本地运行，无需安装Spark的任何集群

    /**
      * 第二步:创建SparkContext对象
      * SparkContext是Spark程序所有功能的唯一入口，无论是采用Scala，Java，Python等都必须有一个SparkContext
      * SparkContext核心作用：初始化Spark应用程序运行所需要的核心组件，包括DAGScheduler，TaskScheduler，Scheduler
      * 同时还会负责Spark程序往Master注册程序等
      * SparkContext是整个Spark应用程序中最为至关重要的一个对象。
      */

    val sc = new SparkContext(conf) //创建SparkContext对象，通过传入SparkConf实例来定制Spark运行的具体参数和配置信息
    `
    
### 笔记要点
    
    1,excutor是运行在worker服务节点为当前应用程序开启的进程里面的一个对象，这个对象负责了具体task的运行
      excutor如何运用：利用线程池的并发和线程复用的形式     一个worker（默认情况下）只会为当前应用程序开辟一个excutor

    2，应用程序的运行不需要cluser manager(既可以用 Spark 自己的 Standlone Cluster Manager，或者 Mesos，也可以使用 YARN）的参与

    3，worker管理当前的NODE计算资源，并接受master的指令分配具体的计算资源Excutor（在新的进程中分配）
       ExcutorRunner：代理管理新分配的进程，创建新的进程
       worker（进程）向master发送心跳时不会汇报自身的资源情况（机器的内存和cup），而是只回报了自己的机器id，
       因为master在为应用程序分配资源的时候就已经记住 了worker的资源信息。
       如果出现excutor lost（容错） worker会向master汇报 并动态调节资源

    4，spark 快的原因： 绝不是因为基于内存的计算  更是因为它的 调度和容错机制

    5，stage 内部计算逻辑完全一样  只是计算的数据不同罢了

    6，一个partition不一定是一个block块  因为记录可能存在跨两个block块

    7，一般一个application对一个job ，但是一个application里面可以有多个job（checkpoint，排序算法）

    8，Driver专门来提交spark程序的机器，这台机器一般一定和spark cluster在同样的网络环境中（因为：
       driver需要频繁的和Excutors通信，且配置和普通的worker一致）

    9，SparkContext: 创建DAGScheduler，TaskScheduler，SchedulerBackend
       在实例化的过程中Register当前程序给master，master接受注册，如果没有问题，master会为当前程序分配appid和计算资源

    10:数据的本地性什么时候确定？
       当DAGSchduler划分stage时确定的，  taskSchduler会把每个stage中的一系列的task发送给每个excutor，发送的依据就是根据数据的本地性！
    
### Spark 运行原理图
   
    ![](https://github.com/xingxingt/xingxingt.github.io/tree/master/img/blog-img/spark-runtime-flow.png)


