#### 环境
    spark:  2.1.1
    hadoop: 2.4.6
    java:   1.8
    scala:  2.11.8
    数据集大小: 1GB,2.1GB,5.2GB    
    执行资源:Executor_number*Executor_core :  6*6

#### 先抛出问题   

用sparkCore做计算时，有一个job运行特别缓慢，跑了将近30~40s,很慢.... 如下图: 
![](https://ws2.sinaimg.cn/large/006tNc79gy1g5m8imbsvgj32io0e4abp.jpg)   



#### 解决问题

先看web ui的详细信息,如下图:
![](https://ws3.sinaimg.cn/large/006tNc79gy1g5m8srycz5j32560gythm.jpg)
![](https://ws4.sinaimg.cn/large/006tNc79gy1g5m8ra3ihgj32560mswth.jpg)

根据web ui展示的executor中task的执行时间确实挺长，根据第一个图可以看到，我使用的spark core的aggregate算子，顺便来拜访下源码,对该算子稍作解释:
aggregate函数将每个分区里面的元素进行聚合，然后用combine函数将每个分区的结果和初始值(zeroValue)进行combine操作。这个函数最终返回的类型不需要和RDD中元素类型一致。我程序汇总使用aggregate算子每个partition中做计算，然后再聚合每个partition的计算结果;  
```scala
/**
   * Aggregate the elements of each partition, and then the results for all the partitions, using
   * given combine functions and a neutral "zero value". This function can return a different result
   * type, U, than the type of this RDD, T. Thus, we need one operation for merging a T into an U
   * and one operation for merging two U's, as in scala.TraversableOnce. Both of these functions are
   * allowed to modify and return their first argument instead of creating a new U to avoid memory
   * allocation.
   *
   * @param zeroValue the initial value for the accumulated result of each partition for the
   *                  `seqOp` operator, and also the initial value for the combine results from
   *                  different partitions for the `combOp` operator - this will typically be the
   *                  neutral element (e.g. `Nil` for list concatenation or `0` for summation)
   * @param seqOp an operator used to accumulate results within a partition
   * @param combOp an associative operator used to combine results from different partitions
   */
  def aggregate[U: ClassTag](zeroValue: U)(seqOp: (U, T) => U, combOp: (U, U) => U): U = withScope {
    // Clone the zero value since we will also be serializing it as part of tasks
    var jobResult = Utils.clone(zeroValue, sc.env.serializer.newInstance())
    val cleanSeqOp = sc.clean(seqOp)
    val cleanCombOp = sc.clean(combOp)
    val aggregatePartition = (it: Iterator[T]) => it.aggregate(zeroValue)(cleanSeqOp, cleanCombOp)
    val mergeResult = (index: Int, taskResult: U) => jobResult = combOp(jobResult, taskResult)
    sc.runJob(this, aggregatePartition, mergeResult)
    jobResult
  }

```

ok,根据前面来做初步的判断，有可能是我的分区数过少，导致并行度达不到，那就来增加平行度试下呗!先对入口的RDD做repartition操作，使分区去扩大两倍，再观察下具体的执行情况:   
![](https://ws2.sinaimg.cn/large/006tNc79gy1g5matih8faj31lr0u0e6a.jpg)


观察上图可以看出，每个task处理的数据量变得小了很多，可是总的执行却没降下来，如下图：  
![](https://ws1.sinaimg.cn/large/006tNc79gy1g5mawxcpjij32ja0i2q58.jpg)  

好吧，看来不是并行度的问题,那就继续观察任务的执行情况,通过查看两次程序(未扩大并行度和扩大并行度)的运行情况可以看出程序GC时间过长:
![](https://ws4.sinaimg.cn/large/006tNc79gy1g5mb4m5zdoj324w0n2k6u.jpg)
![](https://ws1.sinaimg.cn/large/006tNc79gy1g5mb5faqffj325q0o8qkw.jpg)

其实在每个task的执行详情可以看出，每个task执行的gc时间过长，一般都在十几毫秒, 但是两次运行有点深圳GC时间要5s，那这里肯定有问题,那就看业务代码喽,根据代码逻辑发现在我的程序中会生成很多`ValueInfo`对象,en...，很有可能是这里的问题；  
```scala  
    val resultMap = rpRdd.aggregate(initMap)(
      seqOp = (map, data) => {
        columnToIndex.foreach(c => {
          if (data.isNullAt(c._2)) {
            map(c._1).abnormalCount += 1
          } else {
            map(c._1).normalCount += 1
            if (targetName.isEmpty) { 
              if (map(c._1).valueInfoMap.contains(data.getAs(c._2))) {
                map(c._1).valueInfoMap(data.getAs(c._2))(0).value += 1
                map(c._1).valueInfoMap(data.getAs(c._2))(0).totalCount += 1
              } else {
                map(c._1).valueInfoMap.put(data.getAs(c._2), Array(ValueInfo(data.getAs(c
                  ._2), 1, "1", 1)))
              }
            } else { 
              if (map(c._1).valueInfoMap.contains(data.getAs(c._2))) {
                if (data.getAs(targetName) == targetValue0) {
                  map(c._1).valueInfoMap(data.getAs(c._2))(0).value += 1
                } else {
                  map(c._1).valueInfoMap(data.getAs(c._2))(1).value += 1
                }
              } else {
                val array = if (data.getAs(targetName) == targetValue0) Array(ValueInfo
                (targetValue0, 1, ""), ValueInfo(targetValue1, 0, "")) else Array(ValueInfo
                (targetValue0, 0, ""), ValueInfo(targetValue1, 1, ""))
                map(c._1).valueInfoMap.put(data.getAs(c._2), array)
              }
            }
          }
        })
        map
      },
      //由于代码过多这里就不全部展示
```


继续验证上述问题，本地debug跑该程序，祭出jvisualvm，找到本地启动的程序进程,右边选择Profiler,下面的性能分析选择内存，这里会展示你程序对象的创建次数以及占用的内存，一目了然(该图暂做演示，稍后换真实应用)：
![](https://ws4.sinaimg.cn/large/006tNc79gy1g5mbkf1jxnj32fk0kwjst.jpg)   


经过上图可以看到`ValueInfo`对象确实创建过多，导致jvm的堆内存出现GC过长，通过计算，测试环境100w的数据量，会产生65w该对象，是不是疯了(啪啪啪打脸)......,赶紧修改代码，改为字符串或者其他数据结构来存储,修改过后的效果还是挺不错的，该job在未扩展并行度的情况下执行时间由原来的39s降到了3.89s,en.....,Nice

    补图中.....
    
    
再扩充2倍的数据量，大约2.5GB的数据量，该job在未扩展并行度的情况下执行时间为5.39s,继续扩充数据量到5.2GB，该job在未扩展并行度的情况下执行时间为17s，en...还可以；   


    补图中......
    
    
    
#### 总结： 
    当然该该程序还有继续优化的空间，不过在算子函数中使用对象或者复杂的数据结构确实很不好，而且Spark官方建议，在Spark编码实现中，    
    特别是对于算子函数中的代码，尽量不要使用对象，尽量使用字符串替代对象，使用原始类型（比如Int、Long）替代字符串，使用数组替代集合类型，    
    这样尽可能地减少内存占用，从而降低GC频率，提升性能；      
    
    ref:https://tech.meituan.com/2016/05/12/spark-tuning-pro.html     
    ref:https://tech.meituan.com/2016/04/29/spark-tuning-basic.html    














