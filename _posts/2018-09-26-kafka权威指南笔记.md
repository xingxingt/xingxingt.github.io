---
layout:     post
title:      Kafka权威指南笔记
subtitle:   Kafka权威指南阅读笔记
date:       2018-09-27
author:     XINGXING
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Kafka
---

>
>一点一滴学习
>

### Kafka常规配置:

    Log.retention.ms
    根据时间来判断数据可以保留多久，有三个可用的参数:log.retention.hours,log.retention.minutes,
    log.retention.ms 三个参数的作用是一样的，但是如果配置了多个参数，Kafka会优先使用具有最小值的那个参数；

    Log.retention.bytes
    通过保留的消息字节数来判断消息是否过期，它是作用于每个partition上的，例如一个topic有8个分区，
    Log.retention.bytes设置为1G那么这个topic最多可以保存8G的数据，当topic的partition数增多时，
    那么整个Topic能保存数据也随之增加；
    
    Log.segment.bytes
    当消息到达broker时，他们被追加到partition的当前日志片段上，当日志片段达到Log.segment.bytes（默认1G）
    设置的上限时，该日志片段就会被关闭，并生成一个新的日志片段，如果一个日志片段被关闭，那么就开始等待着过期，
    如果这个值调的过小就会频繁的关闭和分配新文件影响性能；
    
    Message.max.bytes
    限制单条消息的大小，默认1M（压缩后的消息）
    
    
### kafka生产者:
    有三种发送消息的方式：1，发送并忘记，2，同步，3，异步
    
    ack机制：
    Ack=0:生产者在成功写入消息之前不会等待任何服务器的响应；
    Ack=1:只要集群的leader接收到消息，生产者就会收到一个来自服务器的成功响应；
    Ack=all：只有当所有参与与复制的服务器全部都收到消息时，生产者才能收到一个来自服务器的成功响应；

    Buffer.memory
    用来设置生产者内存缓冲区的大小，生产者用这个来缓冲要发送到broker的消息；
    
    Comperession.type
    指定消息在发送给broker之前采用哪种压缩方式，snappy,gzip,lz4…..
    
    Retries
    生产者有可能会收到服务器的错误，它指定生产者可以重发消息的次数，如果达到这个次数生产者会放弃重试并返回错误；
    
    Batch.size
    指定一个批次可以使用的内存大小，按照字节来计算；
    
    Lingers.ms
    指定在生产者在发送批次之前等待更多的消息加入批次的时间，以便提高吞吐量；
    
    Client.id
    消息id
    
    Max.in.flight.request.per.connection
    指定生产者在收到服务器相应之前可以发送多少个消息；设置为1，可以保证消息按照发送的顺序写入服务器，即使发生重试；
    
    Request.timeout.ms
    指定生产者再发送数据时等待服务器返回相应的时间；

    Metadata.fatch.timeout.ms
    指定生产者在获取元数据时等待服务器返回响应的时间；
    
    Timeout.ms
    指定broker等待同步副本返回消息确认的时间，与ask搭配使用；
    
    Max.block.ms
    指定调用send()或者partitionsFor()方法获取元数据时阻塞的时间；
    
    Max.request.size
    控制单条消息的最大值；

### Kafka消费者:
    消费者是通过kafkaConsumer.poll()方法向GroupCoordinator发送心跳；
    
    消费者的再均衡:
    分区的所有权从一个消费者移到另一个消费者，这样的行为就叫做再均衡，它可以为消费组带来高可用和伸缩性，但是
    再均衡会使消费组在一段时间的不可用，如果当分区被重新分配给另外一个消费者，那么这个消费者的读取状态会丢失，
    需要去重新刷新缓存，在它重新恢复状态之前会拖慢应用程序；
    
    Fetch.min.bytes
    指定消费者从服务器获取记录的最小字节，如果broker收到消费者的数据请求时，如果可用的数据小于这个设置的值，则
    会等待到有足够数据时再返回给消费者；
    
    Fetch.max.wait.ms
    默认500ms，如果broker收到消费者的数据请求时，如果没有达到获取最小数据量的要求，则会延迟500ms再响应消费者；
    
    Max.partition.fetch.bytes
    指定服务器从每个分区里返回给消费者的最大字节数，默认1MB；也就是说kafkaConsumer.poll();从每个分区里返回的
    记录最多不超过max.partition.fetch.bytes设定的值；
    
    Session.timeout.ms
    指定消费者被认为死亡之前可以与服务器断开链接时间，默认3s；此属性与heartbeat.interval.ms紧密相关；
    
    Auto.offset.reset
    Latest:在偏移量无效的情况下，消费者将从最新的记录开始读取数据；
    Earliest:在偏移量无效的情况下，消费者将从起始位置读取分区的记录；
    
    Enable.auto.commit
    是否启动自动提交偏移量的设置，默认true；
    
    Partition.assignment.strategy
    指定分区分配给消费者策略
    Range：会把topic的若干个连续的分区分配给消费者；
    RoundRobin：把topic的所有分区逐个分配给消费者；
    
    Client.id
    broker用来标识客户端发来的消息；
    
    Max.poll.records
    控制单次调用call()能返回的记录数量，可以控制在轮询的时候处理的数据量；
    
    独立消费者缺点: 如果Topic 新增加了分区，消费者不会收到通知；不会发生再均衡;
    
    
### 深入kafka:
##### 控制器：
    kafka使用Zookeeper的临时节点来选举控制器，并且在节点加入或者退出时通知控制器；控制器负责节点
    的加入或者离开集群时分区leader的选举；控制器使用epoch来避免出现脑裂的情况；

##### 生产者发送压缩过的消息:
    如果生产者发送过来的消息是压缩过的消息，那么同一批次的消息会被压缩在一起，被当做”包装消息“
    来发送，消费者接收到这样的一个消息后解压会看到整个批次的消息，他们有自己的时间戳和offset,
    也就是说生产者端使用压缩功能那么发送的批次越大，就意味着网络传输和磁盘存储方面会获得更好的压缩性能。

##### 数据传递的可靠性保证:
    1，Kafka可以保证分区消息的顺序（同一个生产者写入同一个分区）;
    2，只有当消息被写入分区的所有同步副本时，才被认为是已提交;
    3，只要还有一个副本时活跃的，那么已经提交的消息就不会丢失；
    4，消费者只能读取已经提交的消息;

##### 基于broker数据可靠性的配置:
    1，复制系数
    主题级别的配置参数:replication.factor,设置副本的个数，而在broker级别的配置使用default.replication.factor；
    2，不完全的首领选举
    只能是broker级别的配置,unclean.leader.election=true;就是允许不同步的副本成为leader，这会面临数据丢失的风险，如果
    设置为false，那么就要等待挂掉的leader重新上线，从而降低了可用性；这可根据业务系统对可用性的要求来进行选择；
    3，最少同步副本
    Min.insync.replicas=n,设置至少要存在n个同步副本才能向分区写入数据，如果同步副本数<n，那么这个分区就会变成只读分区
    消费者正常消费，但是无法写入;

##### 基于生产者可靠性的配置:
    1，发送确认,通过ack机制来进行控制;
    2，对于消息发送失败，broker返回错误信息的处理，例如broker返回一些重试可解决的错误码，例如:Leader_not_available,
    分区的leader正在选举，此时可以重新发送此条消息来解决；另外还有一些不可重试错误，Invalid_config错误，这些错误可以
    被记录；还有就是重试发送消息带来重复数据的风险，有可能生产者发送消息，broker保存成功，但是可能网络问题导致生产者
    并未接收到broker的响应，导致生产者将相同的消息再次发送给broker，一般可以将消息加上一个唯一标识来在消费端来处理消息
    重复的情况；
    
##### 基于消费者可靠性的配置:
    1，group.id的设置，多个消费者只能消费相同主题分区的某个子集，不能看到主题的所有消息；
    2，auto.offset.reset 指定在没有偏移量可提交的情况下或者请求的偏移量在broker不存在的情况下，消费者该如何消费，
       earliest：消费者从分区的开始位置读取数据，这样有可能造成重复数据；latest：消费者从分区的末尾开始读取数据，
       这样有可能会丢失数据；
    3，enable.auto.commit 自动提交消费者已经处理过的偏移量，在调用轮询方法时把上一次调用返回的偏移量提交上去；
    4，auto.commit.interval.ms 自动提交偏移量的频率  默认5s；    
